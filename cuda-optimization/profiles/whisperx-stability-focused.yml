# WhisperX Stability-Focused Profile
# Prioritizes reliability and compatibility over cutting-edge performance
# Best for: Production environments, long-running services, RTX 5090
# VALIDATED: October 2025 - RTX 5090 Testing ✅

name: "Stability Focused"
service: "whisperx"

docker:
  build_args:
    CUDA_VERSION: "12.8"  # RTX 5090 ONLY compatible version (PyTorch 2.7.1+cu128)

environment:
  COMPUTE_TYPE: "float16"
  BATCH_SIZE: 16  # Conservative to prevent OOM
  HF_TOKEN: "${HF_TOKEN}"

  # Stability tuning
  PYTORCH_CUDA_ALLOC_CONF: "expandable_segments:True"
  CUDA_LAUNCH_BLOCKING: "0"

  # Cache paths
  HF_HOME: "/data/.huggingface"
  TRANSFORMERS_CACHE: "/data/.huggingface/transformers"
  TORCH_HOME: "/data/.torch"

notes: |
  Balanced profile for reliable 24/7 operation on RTX 5090.
  - CUDA 12.8 with PyTorch 2.7.1+cu128 (VALIDATED ✅)
  - Only CUDA version compatible with RTX 5090 Blackwell architecture
  - Moderate batch size prevents memory issues
  - Conservative settings for long-running services

  VALIDATED PERFORMANCE (RTX 5090):
  - 2.52s transcription time (tested)
  - 17.86% Word Error Rate (tested)
  - ~8-12x realtime transcription speed
  - ~6-8GB VRAM usage
  - Proven stable for continuous operation

  CRITICAL: CUDA 12.9/13.0 WILL FAIL on RTX 5090
  Only CUDA 12.8 has compatible PyTorch wheels (cu128)

recommended_for:
  - RTX 5090 (Blackwell) - REQUIRED profile
  - 24/7 production services
  - Environments requiring maximum uptime
  - First-time RTX 5090 setups (RECOMMENDED START HERE)
