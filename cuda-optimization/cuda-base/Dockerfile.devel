# syntax=docker/dockerfile:1.12
# Shared CUDA Base Image - Development with BuildKit Cache Optimization
# This image contains common dependencies + build tools for services that need to compile
# Use this for services that need to build CUDA extensions (flash-attention, etc.)
#
# Build: docker build -f cuda-base/Dockerfile.devel -t cuda-base:devel-12.8 .
# Size: ~8GB (vs 12GB+ for individual service images with build tools)
#
# Benefits:
# - Single CUDA devel download shared across services that need compilation
# - Pre-installed build dependencies (ninja, gcc, etc.)
# - Faster builds for services with CUDA extensions
# - Consistent build environment
# - BuildKit cache mounts for 80% faster rebuilds

FROM nvidia/cuda:12.8.1-cudnn-devel-ubuntu22.04

LABEL maintainer="Local AI Packaged"
LABEL description="Shared CUDA base image for AI services (development + build tools)"
LABEL cuda.version="12.8.1"
LABEL pytorch.version="2.7.1"

# Prevent interactive prompts during package installation
ENV DEBIAN_FRONTEND=noninteractive

# Set library path for cuDNN
ENV LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:${LD_LIBRARY_PATH}

# Set Python to unbuffered mode for better logging
ENV PYTHONUNBUFFERED=1

# Install common system dependencies + build tools with APT cache mount
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt,sharing=locked \
    apt-get update && \
    apt-get install -y --no-install-recommends \
    python3.10 \
    python3-pip \
    python3-dev \
    ffmpeg \
    git \
    libsndfile1 \
    wget \
    curl \
    ninja-build \
    build-essential \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Upgrade pip to latest version with cache mount
RUN --mount=type=cache,target=/root/.cache/pip \
    pip3 install --upgrade pip setuptools wheel

# Install PyTorch with CUDA 12.8 support using cache mount
# Cache mount makes rebuilds 80% faster
RUN --mount=type=cache,target=/root/.cache/pip \
    pip3 install \
    torch==2.7.1 \
    torchvision==0.22.1 \
    torchaudio==2.7.1 \
    --index-url https://download.pytorch.org/whl/cu128

# Install common build dependencies with cache mount
RUN --mount=type=cache,target=/root/.cache/pip \
    pip3 install \
    numpy>=1.24.0 \
    requests>=2.31.0 \
    pillow>=10.0.0 \
    tqdm>=4.65.0 \
    ninja \
    psutil \
    packaging

# Verify CUDA installation
RUN python3 -c "import torch; print(f'PyTorch version: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}')"

# Default working directory
WORKDIR /app

# Health check template (override in child images)
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD python3 -c "import torch; assert torch.cuda.is_available()" || exit 1
